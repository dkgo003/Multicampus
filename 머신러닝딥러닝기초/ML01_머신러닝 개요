{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Dr3NPVJyHJXbLxf6adNhu5I634oXXbDu","timestamp":1681076947352},{"file_id":"1nsd6tO7gYlwtGC-0J74VCV3CKboZ7Kin","timestamp":1667952543475},{"file_id":"1sCfx0dytsZ1G3lZn3eTYE4RxsJ_vKLUr","timestamp":1659317401751}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 1. 머신러닝(Machine Learning) 개요\n","\n","## Machine Learning, 기계 학습, 機械學習\n","\n","- 컴퓨터 프로그램이 데이터와 처리 경험을 이용한 학습을 통해 정보 처리 능력을 향상시키는 것 또는 이와 관련된 연구 분야\n","- 기계 학습은 자율 주행 자동차, 필기체 문자 인식 등과 같이 알고리즘 개발이 어려운 문제의 해결에 유용\n","- 머신러닝의 기본 모형\n","$$\\hat Y=f(x)$$\n","```\n","가지고 있는 데이터 x를 학습하여 생성한 함수 f( )에 넣으면 \n","그 결과로 어떤 문제에 대한 예측치 Y(hat)을 생성. \n","머신러닝은 우리가 찾고자 하는 f( )를 제공\n","```\n","\n","\n","\n","#### Arthur Samuel (1901 ~ 1990)\n","\"명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을\n","갖추게 하는 연구 분야\"\n","\n","- 1959년 Machine Learning 이라는 용어를 대중화한 개척자\n","- 체커 프로그램으로 세계 최초의 성공적인 자기 학습 프로그램 중 하나로 인공 지능의 기본 개념에 대한 시연\n","http://webdocs.cs.ualberta.ca/~chinook/project/legacy.html\n","\n","#### Tom Mitchell (1951 ~, 카네기 멜론 대학 컴퓨터 과학 교수)\n","\n","“어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때 경험 E로 인해 성능이 향상됐다면, 이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것이다.”  \n","\n","![](https://i0.wp.com/www.zldoty.com/wp-content/uploads/2017/04/2017-04-06-001-Machine-Learning-Definition-ETP-Framework.png?w=1003&ssl=1)\n","\n","\n","- 출처: https://www.zldoty.com/what-is-machine-learning/\n"],"metadata":{"id":"vZKCCdzGmzRQ"}},{"cell_type":"markdown","source":["\n","# 2. 머신러닝의 주요 알고리즘\n","```\n","- 알고리즘 : 어떠한 문제를 해결하기 위한 일련의 절차나 방법\n","- 모델(model) : 상관관계를 식으로 표현한 것 (y=ax+b).알고리즘을 통해 적합한 a와 b를 찾는다면 새로운 값에 대한 결과를 예측 가능하다\n","```\n","\n","### 확률적 모델링\n","- 통계학 이론을 데이터 분석에 응용\n","- 초창기 머신러닝 형태 중 하나\n","- 나이브 베이즈(Naive Bayes)\n","- 로지스틱 회귀\n","\n","### 신경망\n","- 1세대 : Perceptron\n","- 2세대 : Multilayer Perceptron, Back Propagation\n","- 3세대 : Boltzmann Machine, ReLU, Dropout, Local Minima\n","\n","### 커널(Kernel) 방법\n","- 분류 알고리즘의 한 종류\n","- 서포트 벡터 머신(support vector machine)\n","\n","### 결정 트리\n","- 랜덤 포레스트\n","- 그래디언트 부스팅\n","\n"],"metadata":{"id":"oAg6tCRA9Q_t"}},{"cell_type":"markdown","source":["# 3. 머신러닝과 AI\n","\n","\n","![](https://blogs.nvidia.com/wp-content/uploads/2016/07/Deep_Learning_Icons_R5_PNG.jpg-672x427.png.webp)\n","\n","https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/\n","\n","- 인공지능: 사람처럼 학습하고 추론할 수 있는 시스템을 만드는 기술(강인공지능과 약인공지능)\n","- 머신러닝: 규칙을 프로그래밍하지 않아도 자동으로 데이터에서 규칙을 학습하는 알고리즘을 연구하는 분야.\n","- 딥러닝: 인공 신경망을 기반으로 하는 머신러닝 기술\n","\n","## 머신러닝의 역사\n","![](https://hongong.hanbit.co.kr/wp-content/uploads/2021/10/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%9D%98-%EC%97%AD%EC%82%AC-2-1200x353.png)\n","- 혼자 공부하는 머신러닝 딥러닝 26p\n","\n","## 빅데이터와 머신러닝의 관계\n","![](data:image/jpeg;base64,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)\n","\n","https://www.slideshare.net/yongho/ss-48642508\n","\n","\n","- 빅데이터(big data) : 기존의 데이터베이스로는 수집·저장·분석을 수행하기 어려울 만큼 방대한 양의 데이터(데이터베이스에서 기원)\n","- 빅데이터 시스템(big data system) : 빅데이터를 다루기 위한 시스템\n","- 빅데이터 엔지니어링(big data engineering) : 빅데이터를 다루는 방법\n","머신러닝과 별개로 발전해왔으나 대용량 데이터가 학습 성능에 크게 영향을 미치는 오늘날 머신러닝 분야에서 의미 있게 사용됨\n","\n","## 어플리케이션 사례\n","\n","- 이미지 분류 작업: 생산 라인에서 제품 이미지를 분석해 자동으로 분류\n","- 시맨틱 분할 작업: 뇌를 스캔하여 종양 진단\n","- 텍스트 분류(자연어 처리)\n","    - 자동으로 뉴스 기사 분류\n","    - 토론 포럼에서 부정적인 코멘트를 자동으로 구분\n","- 텍스트 요약\n","    - 긴 문서를 자동으로 요약\n","- 자연어 이해 : 챗봇(chatbot) 또는 개인 비서 만들기\n","- 회사의 내년도 수익을 예측하기 : 회귀분석\n","- 음성 인식 : 음성 명령에 반응하는 앱\n","- 이상치 탐지: 신용 카드 부정 거래 감지\n","- 군집 작업 : 구매 이력을 기반으로 고객을 나누고 각 집합마다 다른 마케팅 전략을 계획\n","- 데이터 시각화 : 고차원의 복잡한 데이터셋을 명확하고 의미 있는 그래프로 표현하기\n","- 추천 시스템 : 과거 구매 이력을 기반으로 고객이 관심을 가질 수 있는 상품 추천하기\n","- 강화 학습 : 지능형 게임 봇(bot) 만들기\n","\n","# 머신러닝과 전통적 방식과 차이\n","\n","\n","- 전통적 방법의 경우 사소한 문제가 아닌 경우 규칙이 점점 길고 복잡해져 유지보수가 매우 어려움\n","\n","- 기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 경우라도, 머신러닝 모델 코드를 간단하게 만들 수 있음\n","\n","- 전통적인 방식으로 해결할 수 없는 복잡한 문제를 머신러닝으로 해결 가능\n","\n","![머신러닝의 접근 방법](https://tensorflowkorea.files.wordpress.com/2018/05/e18489e185b3e1848fe185b3e18485e185b5e186abe18489e185a3e186ba-2018-05-23-e1848be185a9e18492e185ae-11-41-57.png?w=625)\n","\n","https://tensorflow.blog/%ED%95%B8%EC%A6%88%EC%98%A8-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-1%EC%9E%A5-2%EC%9E%A5/1-2-%EC%99%9C-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%EC%9D%84-%EC%82%AC%EC%9A%A9%ED%95%98%EB%8A%94%EA%B0%80/\n","\n","### 머신러닝의 장점\n","\n","- 기존 솔루션으로는 많은 조정과 규칙이 필요한 문제들 \n","   - 하나의 머신러닝 모델이 코드를 간단하게 만들고 전통적인 방법보다 더 잘 수행되게 할 수 있음 (팩맨 게임을 만드는 머신러닝 모델)\n","\n","- 전통적인 방식으로는 해결 방법이 없는 복잡한 문제\n","    - 가장 뛰어난 머신러닝 기법으로 해결 방법을 찾을 수 있음\n","    \n","- 유동적인 환경: 머신러닝 시스템은 새로운 데이터에 적응 가능\n","\n","- 복잡한 문제와 대량의 데이터에서 통찰을 얻을 수 있음"],"metadata":{"id":"Tfe6zx6ZDYmz"}},{"cell_type":"markdown","source":["# 4. 머신러닝의 구분\n","\n","![](https://github.com/trekhleb/homemade-machine-learning/blob/master/images/machine-learning-map.png?raw=true)\n","\n","https://github.com/trekhleb/homemade-machine-learning\n","\n","## 머신러닝에 대한 넓은 범주의 분류\n","\n","### 가. 사람의 감독 하에 훈련하는가?  \n","- 지도(Supervised) 학습\n","- 비지도(Unsupervised) 학습\n","- 준지도(Semi-supervised) 학습\n","- 강화(Reinforcement) 학습\n","- 전이(Transfer) 학습\n","\n","\n","### 나. 실시간으로 점진적인 학습을 하는가?\n","- 온라인 학습\n","    - 개별적 또는 소그룹(mini batch)으로 데이터를 순차적으로 공급하여 점진적으로 훈련 \n","    \n","    \n","- 오프라인 학습(배치 학습)\n","    - 시스템이 점진적으로 학습할 수 없음\n","    - 먼저 시스템을 훈련시키고 그런 다음 제품 시스템에 적용하면 더 이상의 학습없이 실행됨\n","    - 모든 데이터를 사용해 학습\n","    - 오프라인으로 수행 (많은 시간과 리소스 사용)\n","    \n","![온라인 학습](https://tensorflowkorea.files.wordpress.com/2018/05/e18489e185b3e1848fe185b3e18485e185b5e186abe18489e185a3e186ba-2018-05-24-e1848be185a9e18492e185ae-6-23-50.png?w=768)   \n"," \n"," \n","    \n","### 다. 데이터 비교 vs 모델 기반인가?\n","- 인스턴스 기반 학습\n","- 모델 기반 학습\n","    \n","\n","# 가. 사람의 감독 하에 훈련하는가?\n","## 지도 학습(Supervised Learning)\n","- 학습 데이터에 입력값(특성)에 대한 출력값(레이블)이 함께 제시됨\n","    - 입력으로 훈련 데이터 세트가 있고 출력으로 각 훈련 세트에 대한 레이블 또는 \"정답\" 세트가 있음\n","    \n","    \n","- 알고리즘은 입력값과 출력값 사이의 관계를 가장 잘 설명할 수 있는 \"모델\"을 찾음\n","\n","\n","- \"모델\"을 사용하여 새로운 입력값에 대한 예측 수행\n","\n","\n","- 출력값이 수치형인 회귀와 범주형인 분류 문제로 나누어 짐\n","\n","\n","- 알고리즘\n","    - k-최근접이웃(K-Nearest Neightbor: KNN)\n","    - 선형 회귀(Linear Regression)\n","    - 로지스틱 회귀(Logistic Regression)\n","    - 서포트 벡터 머신(Support Vector Machine)\n","    - 의사결정트리(Decision Tree)\n","    - 랜덤 포레스트(Random Forest)\n","    - 신경망\n","\n","## 비지도 학습(Unsupervised Learning)\n","- 학습 데이터에 레이블이 지정되거나 분류되지 않은 테스트 데이터에서 학습  \n","\n","\n","- 알고리즘은 학습 데이터의 특징만을 활용하여 목표한 결과를 산출  \n","\n","\n","- 적절한 군집을 찾거나, 변수의 복잡성을 낮추기 위한 차원 축소 등  \n","\n","\n","- GAN(Generative Adversarial Nets) 등과 같은 새로운 기법이 등장하고 있음\n","\n","\n","- 알고리즘\n","    - 군집분석(Clustering)\n","        - K-평균(K-Means)\n","        - 계층적 군집 분석(Hierarchical Cluster Analysis,HCA)\n","        - DBSCAN\n","    - 시각화와 차원축소\n","        - 주성분 분석(Principal Component Analysis, PCA)\n","        - 커널(Kernel) PCA\n","        - 지역적 선형 임베딩(Locally-Linear Embedding, LLE)\n","        - t-SNE(t-distributed Stochastic Neighbor Embedding)\n","    - 이상치 탐지\n","        - 가우스 분포를 이용한 이상치 탐지\n","    - 연관규칙(Association Rule)\n","        - Apriori\n","        - Eclat\n","\n","## 준지도 학습(Semi-supervised Learning)\n","- 모든 데이터에 항상 레이블을 달아 줄 수 있는 것이 없는 현실을 고려한 접근법\n","\n","- 레이블이 달려있는 데이터와 레이블이 달려있지 않은 데이터를 동시에 사용하여 더 좋은 모델을 만들고자 함\n","    - 지도와 비지도 알고리즘 조합     \n","    \n","- 항상 최선의 성능이 발휘되는 것은 아니나, 군집 형태에 가까운 경우 좋은 결과를 나타냄\n","\n","- 알고리즘\n","    - 심층신뢰신경망(DBN)\n","    - 제한된 볼츠만 기계(RBM)\n","\n","## 강화학습(Reinforcement Learning)\n","- 행동심리학에서 영감을 받은 머신러닝 기법\n","- 구체적인 행동에 대한 지시가 없이 목표만 주어짐\n","- 현재 상태에 대한 최선의 액션을 보상에 의해 스스로 찾아 학습하게 하는 방법 \n","- 학습한 내용은 최고의 결과를 얻기 위한 전략으로 활용됨\n","    - Agent인 환경(environment)을 관찰하고 행동(action)을 실행하고 그 결과 보상(reward)을 받음\n","    - 보상을 얻기 위한 정책이라 부르는 최상의 전략(policy)을 스스로 학습\n","- 데이터에서 보지 못한 내용에도 적응하여 반복하면서 더 좋은 결과를 얻을 수 있음\n","\n","\n","- 알고리즘\n","    - SARSA\n","    - Q-Learning\n","\n","![강화학습](https://tensorflowkorea.files.wordpress.com/2018/05/e18489e185b3e1848fe185b3e18485e185b5e186abe18489e185a3e186ba-2018-05-24-e1848be185a9e1848ce185a5e186ab-12-21-44.png?w=768)\n","https://tensorflow.blog/%ed%95%b8%ec%a6%88%ec%98%a8-%eb%a8%b8%ec%8b%a0%eb%9f%ac%eb%8b%9d-1%ec%9e%a5-2%ec%9e%a5/1-3-%eb%a8%b8%ec%8b%a0%eb%9f%ac%eb%8b%9d-%ec%8b%9c%ec%8a%a4%ed%85%9c%ec%9d%98-%ec%a2%85%eb%a5%98/\n","\n","https://www.youtube.com/watch?v=q8i6wHCefU4\n","\n","\n","## 전이학습(Transfer Learning)\n","- 기존의 학습 방법들은 학습에 사용한 데이터와 이후 분석을 하려는 데이터가 같은 분포를 가지고 있다는 가정을 바탕으로 함\n","- 새로운 문제를 해결하고자 할 때 기존에 학습된 모델을 이용하여 새로운 모델을 만드는 방법\n","- 이미 잘 훈련된 모델이 있고, 해결하고자 하는 문제가 유사성이 있을 경우, 학습 데이터가 부족한 경우 등에 사용\n","- 기존의 pre-trained model을 미세 조정하여 사용하는 학습 방법이 대표적"],"metadata":{"id":"ExYPA7-S9h2s"}},{"cell_type":"markdown","source":["\n","# 5. 머신러닝 워크플로우(Workflow)\n","\n","![머신러닝워크플로우](https://content.altexsoft.com/media/2017/04/Screenshot_3.png)\n","\n","https://www.altexsoft.com/whitepapers/machine-learning-bridging-between-business-and-data-science/\n","\n","- Collect data  : 유용한 데이터를 최대한 많이 확보하고 하나의 데이터 세트로 통합\n","- Prepare data  : 결측값, 이상값, 기타 데이터 문제를 적절하게 처리하여 사용 가능한 상태로 준비\n","- Split data :  데이터 세트를 학습용과 평가용 세트로 분리\n","- Train a model :  이력 데이터의 일부를 활용하여 알고리즘이 데이터 내의 \n","패턴을 잘 찾아 주는지 확인\n","- Test and validate a model :  학습 후 모델의 성능을 평가용 데이터 세트로 확인하여 예측 성능을 파악\n","- Deploy a model :  모델을 의사결정 시스템에 탑재 / 적용\n","- Iterate :  새로운 데이터를 확보하고 점진적으로 모델을 개선\n"],"metadata":{"id":"tWr38aFmK09L"}},{"cell_type":"markdown","source":["\n","# 6. 머신러닝 프로젝트 사례\n","\n","## 어플리케이션 사례\n","\n","- 이미지 분류 작업: 생산 라인에서 제품 이미지를 분석해 자동으로 분류\n","- 시맨틱 분할 작업: 뇌를 스캔하여 종양 진단\n","- 텍스트 분류(자연어 처리)\n","    - 자동으로 뉴스 기사 분류\n","    - 토론 포럼에서 부정적인 코멘트를 자동으로 구분\n","- 텍스트 요약\n","    - 긴 문서를 자동으로 요약\n","- 자연어 이해 : 챗봇(chatbot) 또는 개인 비서 만들기\n","- 회사의 내년도 수익을 예측하기 : 회귀분석\n","- 음성 인식 : 음성 명령에 반응하는 앱\n","- 이상치 탐지: 신용 카드 부정 거래 감지\n","- 군집 작업 : 구매 이력을 기반으로 고객을 나누고 각 집합마다 다른 마케팅 전략을 계획\n","- 데이터 시각화 : 고차원의 복잡한 데이터셋을 명확하고 의미 있는 그래프로 표현하기\n","- 추천 시스템 : 과거 구매 이력을 기반으로 고객이 관심을 가질 수 있는 상품 추천하기\n","- 강화 학습 : 지능형 게임 봇(bot) 만들기"],"metadata":{"id":"6CVI1TWfK4xS"}},{"cell_type":"markdown","source":["# 7. 머신러닝의 주요 이슈\n","\n","### 머신러닝의 주요 작업 : 학습 알고리즘을 선택해서 데이터에 훈련시키는 것\n","\n","- **나쁜 데이터**\n","    - 충분하지 않은 양의 데이터\n","    - 대표성 없는 데이터\n","    - 낮은 품질의 데이터 : 오류, 잡음, 이상치\n","    - 연관성이 적은 특성(변수)\n","    \n","    \n","- **나쁜 알고리즘**\n","    - 훈련 데이터 과대적합\n","    - 훈련 데이터 과소적합\n","    \n","![과대적합과 과소적합](https://tensorflowkorea.files.wordpress.com/2017/06/fig2-01.png?w=640)\n","\n","### 테스트와 검증\n","\n","- 모델이 새로운 사례에 잘 일반화 될수 있는가?\n"],"metadata":{"id":"P9WnHXEDITaT"}},{"cell_type":"markdown","source":["# 8. 머신러닝에서 사용되는 주요 패키지\n","\n","머신러닝 패키지\n","- 사이킷런(Scikit-Learn)\n","\n","배열/선형대수/통계 패키지\n","- NumPy\n","- SciPy\n","\n","데이터 핸들링\n","- Pandas\n","\n","시각화\n","- Matplotlib\n","- Seaborn\n","- Plotly\n","\n","딥러닝\n","- 텐서플로(Tensorflow)\n","- 케라스(Keras)\n","- 파이토치(Pytorch)"],"metadata":{"id":"RwYXUIiCLEUi"}},{"cell_type":"markdown","source":["# 9. Deep Learning\n","\n","- 머신러닝의 대표적인 학습법\n","- 기계 학습의 한 분야인 인공 신경망에 기반하여 많은 양의 데이터를 학습해 뛰어난 성능을 이끌어내는 연구 분야\n","- 여러 층을 거쳐 점점 추상화 단계로 접어드는 알고리즘 형태\n","- 패턴을 찾기 위해선, 패턴을 견고하게 만드는 많은 훈련데이터가 필요하다"],"metadata":{"id":"c_0Kx-Cbun6l"}},{"cell_type":"markdown","source":["## 딥러닝과 머신러닝의 차이\n","\n","![](https://images.deepai.org/converted-papers/1808.00033/x2.png)\n","\n","https://deepai.org/publication/techniques-for-interpretable-machine-learning\n"],"metadata":{"id":"Z7CjmXsjQj4Y"}},{"cell_type":"markdown","source":["![](https://miro.medium.com/max/775/0*3pe3IgYQfGFJSx74)\n","\n","https://medium.com/@youlin.li_31343/painters-machine-learning-and-software-engineering-b124e0d6c22b"],"metadata":{"id":"eSqCcTcnPee4"}},{"cell_type":"markdown","source":["## Artificial Neural Network(ANN, 인공신경망)\n","\n","- 인간의 뇌 구조를 모방한 학습기법\n","- 뉴런과 뉴런 사이에는 전기신호를 통해 정보를 전달 \n","\n","* 인공 뉴런(Artificial Neuron)\n","  - 신경세포 구조를 단순화하여 모델링한 구조\n","  - 노드(Node)와 엣지(Edge)로 표현\n","  - 하나의 노드안에서 입력(Inputs)와 가중치(Weights)를 곱하고 더하는 선형구조(linear)\n","  - 활성화 함수(activation function)를 통한 비선형 구조(non-linear) 표현 가능"],"metadata":{"id":"x19h7dRfnZGX"}},{"cell_type":"markdown","source":["## 1) 퍼셉트론(Perceptron)\n","- 로젠 블렛이 1957년에 고안한 알고리즘\n","- 입력 데이터를 2개의 부류중 하나로 분류하는 분류기(Classifier)\n","- 신경세포를 이진 출력의 단순 논리 게이트로 해석하여 고안한 것"],"metadata":{"id":"f4YkF8n6uY72"}},{"cell_type":"markdown","source":["![](https://compmath.korea.ac.kr/appmath2021/_images/neuron-node1.png)\n","\n","https://compmath.korea.ac.kr/appmath2021/_images/neuron-node1.png"],"metadata":{"id":"zocs-LaCuTh_"}},{"cell_type":"markdown","source":["# 활성화함수(activation function)와 편향(bias)"],"metadata":{"id":"QQVY8sTsZ5Q_"}},{"cell_type":"markdown","source":["- 역치와 편견"],"metadata":{"id":"1JNUtHbTZVzo"}},{"cell_type":"markdown","source":["![](data:image/jpeg;base64,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)\n","\n","- 역치(threshold) : 생물체가 자극에 대한 반응을 일으키는 데 필요한 최소한도의 자극의 세기를 나타내는 수치. 우리의 몸은 들어오는 모든 자극을 대뇌로 전송하지 않는다. 따라서 일정 강도 이상의 자극이 가해지지 않으면 자극의 변화를 느낄 수 없는데, 그때의 일정 강도치를 역치라고 한다. \n","물리학에서는 일반적으로 반응이나 기타의 현상을 일으키게 하기 위하여 계(系)에 가하는 물리량의 최소치를 말한다."],"metadata":{"id":"iG9PUrqEVlnQ"}},{"cell_type":"markdown","source":["# 1) Percentron\n","\n","## 뉴런 만들어보기"],"metadata":{"id":"yGb5eQFYpVDW"}},{"cell_type":"code","source":["# 뉴런은 데이터가 통과하는 하나의 클래스로 구성 \n","# 각 뉴런은 랜덤으로 부여받은 가중치(w), 예측값과 실제값의 오차를 누적해서 저장하면서 w를 올바른 방향으로 이끄는 편향(b)를 가지게 됩니다\n","# y = wx + b 라는 모델을 거쳐서 yhat을 출력하게 될거에요.\n","# 최종적으로 그 결과를 밖으로 내보내거나 내보내지 않거나 하는 기준이 되는 활성화함수를 거치게 됩니다. "],"metadata":{"id":"KEvj6qgcSNpW"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1nyZokK7MKTd"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ksLZERzR3n29"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2dR8mqitUEfH"},"source":["## 랜덤한 수 생성"]},{"cell_type":"code","metadata":{"id":"Mq2AtFOl0hS1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681101304875,"user_tz":-540,"elapsed":301,"user":{"displayName":"YeonJi Kim","userId":"14148434577200812637"}},"outputId":"400961a0-c6ca-4446-f5d7-d611697b26fa"},"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","\n","# 가짜 데이터, 랜덤하게 부여되는 가중치를 0과 1 사이 값으로 생성\n","tf.random.uniform([100], 0, 1)  # 균일한 분포의 랜덤한 숫자를 만들어보도록 하겠습니다 "],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(100,), dtype=float32, numpy=\n","array([0.9814756 , 0.13967979, 0.9371637 , 0.99114156, 0.4255246 ,\n","       0.44902158, 0.53634346, 0.9106816 , 0.33497095, 0.3848164 ,\n","       0.8703253 , 0.62993765, 0.7694061 , 0.9713377 , 0.9989228 ,\n","       0.47326243, 0.6840277 , 0.58980405, 0.42917597, 0.48029292,\n","       0.15298843, 0.29993677, 0.31948924, 0.39294124, 0.49192417,\n","       0.3121314 , 0.9330586 , 0.18175721, 0.8054186 , 0.9363669 ,\n","       0.8548107 , 0.15819919, 0.11601722, 0.3765763 , 0.21897638,\n","       0.2845298 , 0.76496565, 0.93168783, 0.49250817, 0.32445323,\n","       0.96865785, 0.04892731, 0.7135831 , 0.38690495, 0.86615396,\n","       0.25392425, 0.64785373, 0.3056053 , 0.22186041, 0.6603123 ,\n","       0.7771566 , 0.79421127, 0.97029245, 0.9862956 , 0.99396384,\n","       0.33832026, 0.5355871 , 0.0188266 , 0.813825  , 0.3787297 ,\n","       0.5753679 , 0.8167683 , 0.92214155, 0.69657886, 0.5078939 ,\n","       0.9871198 , 0.95562136, 0.6745318 , 0.08986056, 0.441795  ,\n","       0.20058   , 0.8321142 , 0.36888957, 0.60278594, 0.90076077,\n","       0.05580425, 0.73552585, 0.51651394, 0.72959244, 0.06428134,\n","       0.1574359 , 0.13981688, 0.26051843, 0.11077487, 0.01732481,\n","       0.5915333 , 0.04753625, 0.50955033, 0.30031943, 0.40710616,\n","       0.9462457 , 0.01925004, 0.7420169 , 0.31644976, 0.5148922 ,\n","       0.24036336, 0.80195355, 0.03421521, 0.31201828, 0.30629623],\n","      dtype=float32)>"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"goJriV4SUL4F"},"source":["## 뉴런 만들기"]},{"cell_type":"code","metadata":{"id":"ilkTV9SKmyP5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681103676604,"user_tz":-540,"elapsed":3341,"user":{"displayName":"YeonJi Kim","userId":"14148434577200812637"}},"outputId":"e6b240d6-fefd-48f2-d638-75b1ae1e6e45"},"source":["# 우리의 목적: 입력이 1이면 0을 출력하는 뉴런을 만들거에요\n","\n","x = 1 # input\n","y = 0 # output\n","\n","# w는 랜덤한 하나의 수에서 시작해서 조금씩 교정을 봐 가지면서 괜찮은 wx+b 라는 수식으로 진화합니다 \n","w = tf.random.uniform([1], 0, 1)\n","\n","# 편향(b)이 없을 때, 활성화함수(activation function)도 없을 때 \n","# y = wx \n","\n","for i in range(10000):                                      # w = 0.3으로 랜덤으로 부여받은 경우\n","    output = x*w # output == yhat == 모델이 예측한 결과    # output = x(1) * x(0.3) \n","    error = y - output # 실제값 - 모델이 예측한 값 (오차)  # 0 - 0.3 = -0.3 \n","    w = w + x * error * 0.1 \n","    # 0.1 : 학습률 - 지금 오차에서 얼마만큼을 반영해서 다음 가중치에 부여할 것인가\n","    # 다음번 데이터가 입력될 때 적용될 가중치 : 0.3 + (1 * -0.3 * 0.1) \n","\n","    # 1000번에 1번씩 w, output, error가 어떻게 바뀌는지 확인해볼게요\n","    if i % 1000 == 999:\n","        print(f'학습횟수: {i}, input: {x}, 모델의예측결과: {output}, 가중치(w): {w}, 오차: {error}')                                                      \n","\n"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["학습횟수: 999, input: 1, 모델의예측결과: [1.1062782e-37], 가중치(w): [1.1062782e-37], 오차: [-1.1062782e-37]\n","학습횟수: 1999, input: 1, 모델의예측결과: [1.1062782e-37], 가중치(w): [1.1062782e-37], 오차: [-1.1062782e-37]\n","학습횟수: 2999, input: 1, 모델의예측결과: [1.1062782e-37], 가중치(w): [1.1062782e-37], 오차: [-1.1062782e-37]\n","학습횟수: 3999, input: 1, 모델의예측결과: [1.1062782e-37], 가중치(w): [1.1062782e-37], 오차: [-1.1062782e-37]\n","학습횟수: 4999, input: 1, 모델의예측결과: [1.1062782e-37], 가중치(w): [1.1062782e-37], 오차: [-1.1062782e-37]\n","학습횟수: 5999, input: 1, 모델의예측결과: [1.1062782e-37], 가중치(w): [1.1062782e-37], 오차: [-1.1062782e-37]\n","학습횟수: 6999, input: 1, 모델의예측결과: [1.1062782e-37], 가중치(w): [1.1062782e-37], 오차: [-1.1062782e-37]\n","학습횟수: 7999, input: 1, 모델의예측결과: [1.1062782e-37], 가중치(w): [1.1062782e-37], 오차: [-1.1062782e-37]\n","학습횟수: 8999, input: 1, 모델의예측결과: [1.1062782e-37], 가중치(w): [1.1062782e-37], 오차: [-1.1062782e-37]\n","학습횟수: 9999, input: 1, 모델의예측결과: [1.1062782e-37], 가중치(w): [1.1062782e-37], 오차: [-1.1062782e-37]\n"]}]},{"cell_type":"code","source":["import math\n","\n","def sigmoid(x): # 시그모이드 함수 \n","    return 1 / (1+math.exp(-x))"],"metadata":{"id":"hiNJNALCmPoF","executionInfo":{"status":"ok","timestamp":1681103895269,"user_tz":-540,"elapsed":298,"user":{"displayName":"YeonJi Kim","userId":"14148434577200812637"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["sigmoid(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1bGlWNUImb_r","executionInfo":{"status":"ok","timestamp":1681103905849,"user_tz":-540,"elapsed":2,"user":{"displayName":"YeonJi Kim","userId":"14148434577200812637"}},"outputId":"a81154ca-3d79-4d93-db76-2ff2bba42c2e"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7310585786300049"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["sigmoid(0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6b6Jil8KmgBF","executionInfo":{"status":"ok","timestamp":1681103916740,"user_tz":-540,"elapsed":2,"user":{"displayName":"YeonJi Kim","userId":"14148434577200812637"}},"outputId":"0bbf7ad2-4a80-40d8-a8f7-b85d51f70b45"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["sigmoid(-1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EgTMCxZQmh2D","executionInfo":{"status":"ok","timestamp":1681103924456,"user_tz":-540,"elapsed":3,"user":{"displayName":"YeonJi Kim","userId":"14148434577200812637"}},"outputId":"1a436600-add1-4ca8-fffe-3229ad85f985"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.2689414213699951"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["sigmoid(1000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KdQJib8Rmj4f","executionInfo":{"status":"ok","timestamp":1681103933012,"user_tz":-540,"elapsed":2,"user":{"displayName":"YeonJi Kim","userId":"14148434577200812637"}},"outputId":"31a9ce6c-6b3f-4237-cf34-fe2d20bed026"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"bmOY52Sj3p0a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681104306451,"user_tz":-540,"elapsed":23413,"user":{"displayName":"YeonJi Kim","userId":"14148434577200812637"}},"outputId":"13fe4f2e-c716-440d-aa00-8faaed99a472"},"source":["# 우리의 목적: 입력이 1이면 0을 출력하는 뉴런을 만들거에요\n","output = 0\n","x = 1 # input\n","y = 0 # output\n","\n","# w는 랜덤한 하나의 수에서 시작해서 조금씩 교정을 봐 가지면서 괜찮은 wx+b 라는 수식으로 진화합니다 \n","w = tf.random.uniform([1], 0, 1)\n","\n","# 편향이 없을 때 \n","# y = wx \n","\n","for i in range(100000):                                      # w = 0.3으로 랜덤으로 부여받은 경우\n","    output = sigmoid(x*w) # 출력된 결과를 0~100 사이의 확률로 출력하는 활성화함수 sigmoid를 적용 \n","    error = y - output # 실제값 - 모델이 예측한 값 (오차)  # 0 - 0.3 = -0.3 \n","    w = w + x * error * 0.1 \n","    # 0.1 : 학습률 - 지금 오차에서 얼마만큼을 반영해서 다음 가중치에 부여할 것인가\n","    # 다음번 데이터가 입력될 때 적용될 가중치 : 0.3 + (1 * -0.3 * 0.1) \n","\n","    # 1000번에 1번씩 w, output, error가 어떻게 바뀌는지 확인해볼게요\n","    if i % 1000 == 999:\n","        print(f'학습횟수: {i}, input: {x}, 모델의예측결과: {output}, 가중치(w): {w}, 오차: {error}')                                                      \n","\n"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["학습횟수: 999, input: 1, 모델의예측결과: 0.010286131009194385, 가중치(w): [-4.567648], 오차: -0.010286131009194385\n","학습횟수: 1999, input: 1, 모델의예측결과: 0.005087899792086957, 가중치(w): [-5.276298], 오차: -0.005087899792086957\n","학습횟수: 2999, input: 1, 모델의예측결과: 0.003376628428353383, 가중치(w): [-5.687833], 오차: -0.003376628428353383\n","학습횟수: 3999, input: 1, 모델의예측결과: 0.0025260348457897073, 가중치(w): [-5.978828], 오차: -0.0025260348457897073\n","학습횟수: 4999, input: 1, 모델의예측결과: 0.0020175031310381403, 가중치(w): [-6.204077], 오차: -0.0020175031310381403\n","학습횟수: 5999, input: 1, 모델의예측결과: 0.0016792941204485754, 가중치(w): [-6.387869], 오차: -0.0016792941204485754\n","학습횟수: 6999, input: 1, 모델의예측결과: 0.0014381435383578275, 가중치(w): [-6.543107], 오차: -0.0014381435383578275\n","학습횟수: 7999, input: 1, 모델의예측결과: 0.001257524980359894, 가중치(w): [-6.6774774], 오차: -0.001257524980359894\n","학습횟수: 8999, input: 1, 모델의예측결과: 0.0011171933571375618, 가중치(w): [-6.7959294], 오차: -0.0011171933571375618\n","학습횟수: 9999, input: 1, 모델의예측결과: 0.001005026076627755, 가중치(w): [-6.901837], 오차: -0.001005026076627755\n","학습횟수: 10999, input: 1, 모델의예측결과: 0.0009133165879223566, 가중치(w): [-6.997606], 오차: -0.0009133165879223566\n","학습횟수: 11999, input: 1, 모델의예측결과: 0.0008369411971070278, 가중치(w): [-7.0850034], 오차: -0.0008369411971070278\n","학습횟수: 12999, input: 1, 모델의예측결과: 0.0007723523638733202, 가중치(w): [-7.1653743], 오차: -0.0007723523638733202\n","학습횟수: 13999, input: 1, 모델의예측결과: 0.0007170115993845439, 가중치(w): [-7.239773], 오차: -0.0007170115993845439\n","학습횟수: 14999, input: 1, 모델의예측결과: 0.0006690708008309527, 가중치(w): [-7.309018], 오차: -0.0006690708008309527\n","학습횟수: 15999, input: 1, 모델의예측결과: 0.0006271345746651668, 가중치(w): [-7.373785], 오차: -0.0006271345746651668\n","학습횟수: 16999, input: 1, 모델의예측결과: 0.0005901490868410893, 가중치(w): [-7.434604], 오차: -0.0005901490868410893\n","학습횟수: 17999, input: 1, 모델의예측결과: 0.0005572803384168664, 가중치(w): [-7.4919405], 오차: -0.0005572803384168664\n","학습횟수: 18999, input: 1, 모델의예측결과: 0.000527877013960901, 가중치(w): [-7.546172], 오차: -0.000527877013960901\n","학습횟수: 19999, input: 1, 모델의예측결과: 0.0005014227498758937, 가중치(w): [-7.5976095], 오차: -0.0005014227498758937\n","학습횟수: 20999, input: 1, 모델의예측결과: 0.0004774916486031967, 가중치(w): [-7.646534], 오차: -0.0004774916486031967\n","학습횟수: 21999, input: 1, 모델의예측결과: 0.0004557364526526011, 가중치(w): [-7.693186], 오차: -0.0004557364526526011\n","학습횟수: 22999, input: 1, 모델의예측결과: 0.0004358802042387863, 가중치(w): [-7.7377505], 오차: -0.0004358802042387863\n","학습횟수: 23999, input: 1, 모델의예측결과: 0.0004176819130066305, 가중치(w): [-7.7804146], 오차: -0.0004176819130066305\n","학습횟수: 24999, input: 1, 모델의예측결과: 0.0004009463473704617, 가중치(w): [-7.821322], 오차: -0.0004009463473704617\n","학습횟수: 25999, input: 1, 모델의예측결과: 0.0003854957770289087, 가중치(w): [-7.8606334], 오차: -0.0003854957770289087\n","학습횟수: 26999, input: 1, 모델의예측결과: 0.00037119199668821443, 가중치(w): [-7.898457], 오차: -0.00037119199668821443\n","학습횟수: 27999, input: 1, 모델의예측결과: 0.00035791215667579576, 가중치(w): [-7.9349008], 오차: -0.00035791215667579576\n","학습횟수: 28999, input: 1, 모델의예측결과: 0.0003455419812475299, 가중치(w): [-7.970085], 오차: -0.0003455419812475299\n","학습횟수: 29999, input: 1, 모델의예측결과: 0.0003340116346922555, 가중치(w): [-8.004034], 오차: -0.0003340116346922555\n","학습횟수: 30999, input: 1, 모델의예측결과: 0.00032321916910650665, 가중치(w): [-8.036889], 오차: -0.00032321916910650665\n","학습횟수: 31999, input: 1, 모델의예측결과: 0.00031310141094679275, 가중치(w): [-8.068702], 오차: -0.00031310141094679275\n","학습횟수: 32999, input: 1, 모델의예측결과: 0.0003035999935020922, 가중치(w): [-8.099526], 오차: -0.0003035999935020922\n","학습횟수: 33999, input: 1, 모델의예측결과: 0.00029466088039556496, 가중치(w): [-8.12942], 오차: -0.00029466088039556496\n","학습횟수: 34999, input: 1, 모델의예측결과: 0.00028623257376781877, 가중치(w): [-8.158448], 오차: -0.00028623257376781877\n","학습횟수: 35999, input: 1, 모델의예측결과: 0.0002782667174380437, 가중치(w): [-8.18668], 오차: -0.0002782667174380437\n","학습횟수: 36999, input: 1, 모델의예측결과: 0.0002707167749009241, 가중치(w): [-8.214193], 오차: -0.0002707167749009241\n","학습횟수: 37999, input: 1, 모델의예측결과: 0.0002635854004164332, 가중치(w): [-8.240896], 오차: -0.0002635854004164332\n","학습횟수: 38999, input: 1, 모델의예측결과: 0.00025684035665062086, 가중치(w): [-8.266825], 오차: -0.00025684035665062086\n","학습횟수: 39999, input: 1, 모델의예측결과: 0.0002504017710430874, 가중치(w): [-8.292218], 오차: -0.0002504017710430874\n","학습횟수: 40999, input: 1, 모델의예측결과: 0.0002442707673665456, 가중치(w): [-8.317014], 오차: -0.0002442707673665456\n","학습횟수: 41999, input: 1, 모델의예측결과: 0.0002384762176519138, 가중치(w): [-8.341026], 오차: -0.0002384762176519138\n","학습횟수: 42999, input: 1, 모델의예측결과: 0.00023289058239371146, 가중치(w): [-8.364732], 오차: -0.00023289058239371146\n","학습횟수: 43999, input: 1, 모델의예측결과: 0.00022762187884616715, 가중치(w): [-8.38762], 오차: -0.00022762187884616715\n","학습횟수: 44999, input: 1, 모델의예측결과: 0.00022254044370995582, 가중치(w): [-8.410201], 오차: -0.00022254044370995582\n","학습횟수: 45999, input: 1, 모델의예측결과: 0.00021771332478744202, 가중치(w): [-8.432136], 오차: -0.00021771332478744202\n","학습횟수: 46999, input: 1, 모델의예측결과: 0.0002130595407966833, 가중치(w): [-8.453747], 오차: -0.0002130595407966833\n","학습횟수: 47999, input: 1, 모델의예측결과: 0.00020863686433412952, 가중치(w): [-8.474728], 오차: -0.00020863686433412952\n","학습횟수: 48999, input: 1, 모델의예측결과: 0.00020433909369685393, 가중치(w): [-8.495545], 오차: -0.00020433909369685393\n","학습횟수: 49999, input: 1, 모델의예측결과: 0.0002002882800287821, 가중치(w): [-8.515573], 오차: -0.0002002882800287821\n","학습횟수: 50999, input: 1, 모델의예측결과: 0.00019631775383298136, 가중치(w): [-8.5356], 오차: -0.00019631775383298136\n","학습횟수: 51999, input: 1, 모델의예측결과: 0.0001925712925636912, 가중치(w): [-8.554871], 오차: -0.0001925712925636912\n","학습횟수: 52999, input: 1, 모델의예측결과: 0.00018893378089315912, 가중치(w): [-8.573944], 오차: -0.00018893378089315912\n","학습횟수: 53999, input: 1, 모델의예측결과: 0.00018539483837403504, 가중치(w): [-8.592855], 오차: -0.00018539483837403504\n","학습횟수: 54999, input: 1, 모델의예측결과: 0.00018206637698950443, 가중치(w): [-8.610975], 오차: -0.00018206637698950443\n","학습횟수: 55999, input: 1, 모델의예측결과: 0.00017879766200395937, 가중치(w): [-8.629095], 오차: -0.00017879766200395937\n","학습횟수: 56999, input: 1, 모델의예측결과: 0.0001756318268396797, 가중치(w): [-8.646962], 오차: -0.0001756318268396797\n","학습횟수: 57999, input: 1, 모델의예측결과: 0.00017264315260906077, 가중치(w): [-8.664128], 오차: -0.00017264315260906077\n","학습횟수: 58999, input: 1, 모델의예측결과: 0.00016970532712102878, 가중치(w): [-8.681294], 오차: -0.00016970532712102878\n","학습횟수: 59999, input: 1, 모델의예측결과: 0.0001668216212254893, 가중치(w): [-8.698435], 오차: -0.0001668216212254893\n","학습횟수: 60999, input: 1, 모델의예측결과: 0.0001641392781770224, 가중치(w): [-8.714647], 오차: -0.0001641392781770224\n","학습횟수: 61999, input: 1, 모델의예측결과: 0.0001615000578484751, 가중치(w): [-8.73086], 오차: -0.0001615000578484751\n","학습횟수: 62999, input: 1, 모델의예측결과: 0.00015890326719916184, 가중치(w): [-8.747072], 오차: -0.00015890326719916184\n","학습횟수: 63999, input: 1, 모델의예측결과: 0.00015640727192658412, 가중치(w): [-8.762906], 오차: -0.00015640727192658412\n","학습횟수: 64999, input: 1, 모델의예측결과: 0.00015403916713690256, 가중치(w): [-8.778165], 오차: -0.00015403916713690256\n","학습횟수: 65999, input: 1, 모델의예측결과: 0.0001517069115077651, 가중치(w): [-8.793424], 오차: -0.0001517069115077651\n","학습횟수: 66999, input: 1, 모델의예측결과: 0.0001494099625061077, 가중치(w): [-8.808682], 오차: -0.0001494099625061077\n","학습횟수: 67999, input: 1, 모델의예측결과: 0.0001471896042483509, 가중치(w): [-8.823656], 오차: -0.0001471896042483509\n","학습횟수: 68999, input: 1, 모델의예측결과: 0.00014509933202346, 가중치(w): [-8.837961], 오차: -0.00014509933202346\n","학습횟수: 69999, input: 1, 모델의예측결과: 0.00014303873997152813, 가중치(w): [-8.852266], 오차: -0.00014303873997152813\n","학습횟수: 70999, input: 1, 모델의예측결과: 0.00014100740677789253, 가중치(w): [-8.866571], 오차: -0.00014100740677789253\n","학습횟수: 71999, input: 1, 모델의예측결과: 0.00013900491710514034, 가중치(w): [-8.880877], 오차: -0.00013900491710514034\n","학습횟수: 72999, input: 1, 모델의예측결과: 0.00013711385884492962, 가중치(w): [-8.894575], 오차: -0.00013711385884492962\n","학습횟수: 73999, input: 1, 모델의예측결과: 0.00013529560417742306, 가중치(w): [-8.907927], 오차: -0.00013529560417742306\n","학습횟수: 74999, input: 1, 모델의예측결과: 0.00013350145800369482, 가중치(w): [-8.921278], 오차: -0.00013350145800369482\n","학습횟수: 75999, input: 1, 모델의예측결과: 0.00013173110075066126, 가중치(w): [-8.934629], 오차: -0.00013173110075066126\n","학습횟수: 76999, input: 1, 모델의예측결과: 0.00012998421707914416, 가중치(w): [-8.947981], 오차: -0.00012998421707914416\n","학습횟수: 77999, input: 1, 모델의예측결과: 0.00012829511226146058, 가중치(w): [-8.9610615], 오차: -0.00012829511226146058\n","학습횟수: 78999, input: 1, 모델의예측결과: 0.00012671455892500214, 가중치(w): [-8.973459], 오차: -0.00012671455892500214\n","학습횟수: 79999, input: 1, 모델의예측결과: 0.0001251534750454328, 가중치(w): [-8.985857], 오차: -0.0001251534750454328\n","학습횟수: 80999, input: 1, 모델의예측결과: 0.00012361162085519156, 가중치(w): [-8.998255], 오차: -0.00012361162085519156\n","학습횟수: 81999, input: 1, 모델의예측결과: 0.0001220887595380081, 가중치(w): [-9.010653], 오차: -0.0001220887595380081\n","학습횟수: 82999, input: 1, 모델의예측결과: 0.00012058465719261131, 가중치(w): [-9.02305], 오차: -0.00012058465719261131\n","학습횟수: 83999, input: 1, 모델의예측결과: 0.0001191074871408222, 가중치(w): [-9.035377], 오차: -0.0001191074871408222\n","학습횟수: 84999, input: 1, 모델의예측결과: 0.00011775233963597862, 가중치(w): [-9.046821], 오차: -0.00011775233963597862\n","학습횟수: 85999, input: 1, 모델의예측결과: 0.00011641260855033336, 가중치(w): [-9.058265], 오차: -0.00011641260855033336\n","학습횟수: 86999, input: 1, 모델의예측결과: 0.0001150881185443454, 가중치(w): [-9.069709], 오차: -0.0001150881185443454\n","학습횟수: 87999, input: 1, 모델의예측결과: 0.00011377869627178927, 가중치(w): [-9.081153], 오차: -0.00011377869627178927\n","학습횟수: 88999, input: 1, 모델의예측결과: 0.00011248417035711515, 가중치(w): [-9.092597], 오차: -0.00011248417035711515\n","학습횟수: 89999, input: 1, 모델의예측결과: 0.0001112043713730658, 가중치(w): [-9.104041], 오차: -0.0001112043713730658\n","학습횟수: 90999, input: 1, 모델의예측결과: 0.00010993913181854696, 가중치(w): [-9.115485], 오차: -0.00010993913181854696\n","학습횟수: 91999, input: 1, 모델의예측결과: 0.00010876988293052378, 가중치(w): [-9.126178], 오차: -0.00010876988293052378\n","학습횟수: 92999, input: 1, 모델의예측결과: 0.00010763492775038668, 가중치(w): [-9.136668], 오차: -0.00010763492775038668\n","학습횟수: 93999, input: 1, 모델의예측결과: 0.00010651181395511594, 가중치(w): [-9.147159], 오차: -0.00010651181395511594\n","학습횟수: 94999, input: 1, 모델의예측결과: 0.00010540041802558556, 가중치(w): [-9.157649], 오차: -0.00010540041802558556\n","학습횟수: 95999, input: 1, 모델의예측결과: 0.00010430061773057096, 가중치(w): [-9.168139], 오차: -0.00010430061773057096\n","학습횟수: 96999, input: 1, 모델의예측결과: 0.00010321229211333164, 가중치(w): [-9.17863], 오차: -0.00010321229211333164\n","학습횟수: 97999, input: 1, 모델의예측결과: 0.00010213532147833343, 가중치(w): [-9.18912], 오차: -0.00010213532147833343\n","학습횟수: 98999, input: 1, 모델의예측결과: 0.0001010695873781088, 가중치(w): [-9.199611], 오차: -0.0001010695873781088\n","학습횟수: 99999, input: 1, 모델의예측결과: 0.00010002594100125685, 가중치(w): [-9.2099905], 오차: -0.00010002594100125685\n"]}]},{"cell_type":"code","metadata":{"id":"SQOfPrld8cde"},"source":["# y = -6.9x + - 0.01006 "],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 우리의 목적: 입력이 0이면 1을 출력하는 뉴런을 만들거에요\n","x = 0 # input\n","y = 1 # output\n","\n","# w는 랜덤한 하나의 수에서 시작해서 조금씩 교정을 봐 가지면서 괜찮은 wx+b 라는 수식으로 진화합니다 \n","w = tf.random.uniform([1], 0, 1)\n","learning_rate =  0.1 \n","# 편향이 없을 때 \n","# y = wx + b   ( 1~10까지 더하는 반복문 만들어주세요 sum_ )\n","\n","for i in range(10000):                                      # w = 0.3으로 랜덤으로 부여받은 경우\n","    output = sigmoid(x*w) # 출력된 결과를 0~100 사이의 확률로 출력하는 활성화함수 sigmoid를 적용 \n","    error = y - output # 실제값 - 모델이 예측한 값 (오차)  # 0 - 0.3 = -0.3 \n","    w = w + x * error * learning_rate\n","    # 0.1 : 학습률 - 지금 오차에서 얼마만큼을 반영해서 다음 가중치에 부여할 것인가\n","    # 다음번 데이터가 입력될 때 적용될 가중치 : 0.3 + (1 * -0.3 * 0.1) \n","\n","    # 1000번에 1번씩 w, output, error가 어떻게 바뀌는지 확인해볼게요\n","    if i % 1000 == 999:\n","        print(f'학습횟수: {i}, input: {x}, 모델의예측결과: {output}, 가중치(w): {w}, 오차: {error}')                                                      \n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kZ_Va7xbpnbW","executionInfo":{"status":"ok","timestamp":1681104752930,"user_tz":-540,"elapsed":2195,"user":{"displayName":"YeonJi Kim","userId":"14148434577200812637"}},"outputId":"1808e4ff-d6d7-49c4-d0b3-e8a0fb356f59"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["학습횟수: 999, input: 0, 모델의예측결과: 0.5, 가중치(w): [0.99715364], 오차: 0.5\n","학습횟수: 1999, input: 0, 모델의예측결과: 0.5, 가중치(w): [0.99715364], 오차: 0.5\n","학습횟수: 2999, input: 0, 모델의예측결과: 0.5, 가중치(w): [0.99715364], 오차: 0.5\n","학습횟수: 3999, input: 0, 모델의예측결과: 0.5, 가중치(w): [0.99715364], 오차: 0.5\n","학습횟수: 4999, input: 0, 모델의예측결과: 0.5, 가중치(w): [0.99715364], 오차: 0.5\n","학습횟수: 5999, input: 0, 모델의예측결과: 0.5, 가중치(w): [0.99715364], 오차: 0.5\n","학습횟수: 6999, input: 0, 모델의예측결과: 0.5, 가중치(w): [0.99715364], 오차: 0.5\n","학습횟수: 7999, input: 0, 모델의예측결과: 0.5, 가중치(w): [0.99715364], 오차: 0.5\n","학습횟수: 8999, input: 0, 모델의예측결과: 0.5, 가중치(w): [0.99715364], 오차: 0.5\n","학습횟수: 9999, input: 0, 모델의예측결과: 0.5, 가중치(w): [0.99715364], 오차: 0.5\n"]}]},{"cell_type":"code","metadata":{"id":"v6QTKN-Y_Pej","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681106042717,"user_tz":-540,"elapsed":3541,"user":{"displayName":"YeonJi Kim","userId":"14148434577200812637"}},"outputId":"8adc2ba9-3b02-41f3-dc5c-2767a0e485a8"},"source":["# 우리의 목적: 입력이 0이면 1을 출력하는 뉴런을 만들거에요\n","x = 1 # input\n","y = 0 # output\n","\n","# w는 랜덤한 하나의 수에서 시작해서 조금씩 교정을 봐 가지면서 괜찮은 wx+b 라는 수식으로 진화합니다 \n","w = tf.random.uniform([1], 0, 1)\n","b = tf.random.uniform([1], 0, 1)\n","learning_rate =  0.1  # 학습률, eta \n","# 0~1사이의 값 기존 가중치에 지금의 오차를 얼마나 누적해서 새 가중치를 부여할 것인가 \n","\n","# 편향이 있을 때 \n","# y = wx + b   ( 편향의 역할: \"1~10까지 더하는 총합을 만들어주세요\"에서 sum_ 라는 누적합용 공갈변수와 같다고 생각하시면 됩니다 )\n","\n","for i in range(10000):                                      # w = 0.3으로 랜덤으로 부여받은 경우\n","    output = sigmoid(x*w + b) # 출력된 결과를 0~100 사이의 확률로 출력하는 활성화함수 sigmoid를 적용 \n","    error = y - output # 실제값 - 모델이 예측한 값 (오차)  # 0 - 0.3 = -0.3 \n","    w = w + x * error * learning_rate\n","    b = b + error * learning_rate\n","    # 0.1 : 학습률 - 지금 오차에서 얼마만큼을 반영해서 다음 가중치에 부여할 것인가\n","    # 다음번 데이터가 입력될 때 적용될 가중치 : 0.3 + (1 * -0.3 * 0.1) \n","\n","    # 1000번에 1번씩 w, output, error가 어떻게 바뀌는지 확인해볼게요\n","    if i % 1000 == 999:\n","        print(f'학습횟수: {i}, input: {x}, 모델의예측결과: {output}, 가중치(w): {w}, 편향(b): {b}, 오차: {error}')                                                      \n","\n"],"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["학습횟수: 999, input: 1, 모델의예측결과: 0.005113302282127793, 가중치(w): [-2.3107975], 편향(b): [-2.961009], 오차: -0.005113302282127793\n","학습횟수: 1999, input: 1, 모델의예측결과: 0.002532084225220402, 가중치(w): [-2.663236], 편향(b): [-3.3134475], 오차: -0.002532084225220402\n","학습횟수: 2999, input: 1, 모델의예측결과: 0.0016819150113556477, 가중치(w): [-2.8681319], 편향(b): [-3.5183434], 오차: -0.0016819150113556477\n","학습횟수: 3999, input: 1, 모델의예측결과: 0.0012589745062172406, 가중치(w): [-3.0131192], 편향(b): [-3.6633308], 오차: -0.0012589745062172406\n","학습횟수: 4999, input: 1, 모델의예측결과: 0.0010059399505279606, 가중치(w): [-3.1254082], 편향(b): [-3.7756197], 오차: -0.0010059399505279606\n","학습횟수: 5999, input: 1, 모델의예측결과: 0.0008375694648792589, 가중치(w): [-3.217062], 편향(b): [-3.8672736], 오차: -0.0008375694648792589\n","학습횟수: 6999, input: 1, 모델의예측결과: 0.0007174688762503306, 가중치(w): [-3.2944977], 편향(b): [-3.9447093], 오차: -0.0007174688762503306\n","학습횟수: 7999, input: 1, 모델의예측결과: 0.0006274819385712661, 가중치(w): [-3.36154], 편향(b): [-4.0117536], 오차: -0.0006274819385712661\n","학습횟수: 8999, input: 1, 모델의예측결과: 0.0005575505026574877, 가중치(w): [-3.4206512], 편향(b): [-4.0708604], 오차: -0.0005575505026574877\n","학습횟수: 9999, input: 1, 모델의예측결과: 0.000501638592625892, 가중치(w): [-3.4735105], 편향(b): [-4.1237183], 오차: -0.000501638592625892\n"]}]},{"cell_type":"markdown","source":["- 뉴런 학습이란? 에러가 0에 가까워지게 기댓값에 가까운 값을 얻는 것...\n","    - W값을 얻기 위에 변화하는 알고리즘?\n","        - 경사 하강법(Gradient Descent)\n","            - w에 입력과 학습률과 에러를 곱한 값을 더해주는 것\n","- 편향이란?\n","    - 입력으로는 늘 한쪽으로 치우친 고정된 값(예, 1)을 받아서 입력으로 0을 받았을 때 뉴런이 아무것도 배우지 못하는 상황을 방지"],"metadata":{"id":"0l1sYxVAbLZD"}},{"cell_type":"code","source":[],"metadata":{"id":"jtSAz-KEfzU1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- https://teachablemachine.withgoogle.com/"],"metadata":{"id":"w2kVsjzAf36F"}},{"cell_type":"code","source":[],"metadata":{"id":"s1rn9H4Gf4gs"},"execution_count":null,"outputs":[]}]}