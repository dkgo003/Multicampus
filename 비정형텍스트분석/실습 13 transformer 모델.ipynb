{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNe4eKY4C1ow9ucqur7Rg/s"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## 데이터 불러오기"],"metadata":{"id":"qAqXoVT_Zdb7"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j7B5VgwXY8Oa","outputId":"48b959a9-ce07-4095-a083-f2edcc8a6679"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["### 구글 서버와 내 드라이브 연결하기\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["### 작업 디렉토리 변경하기\n","%cd '/content/drive/MyDrive/KDT/비정형텍스트분석'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W-9ADG1sZfJA","outputId":"81a5250c-c0f0-4c93-8aad-e6bf77876380"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/KDT/비정형텍스트분석\n"]}]},{"cell_type":"code","source":["### 필요한 라이브러리 임폴트\n","import tensorflow as tf\n","import numpy as np\n","import re\n","import json\n","import matplotlib.pyplot as plt"],"metadata":{"id":"qcx1apAga_tp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### 저장된 결과 불러오기\n","enc_inputs = np.load('enc_inputs.npy')\n","dec_inputs = np.load('dec_inputs.npy')\n","dec_targets = np.load('dec_targets.npy')\n","with open('data_configs.json', 'r') as f:\n","    data_configs = json.load(f)"],"metadata":{"id":"PooIlcgXbXRl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 랜덤 시드 설정"],"metadata":{"id":"F95ACLuYb0TP"}},{"cell_type":"code","source":["tf.random.set_seed(99)\n","np.random.seed(99)"],"metadata":{"id":"fVreBEDlb2kc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 모델 하이퍼파라미터 정의"],"metadata":{"id":"mlJVBtY9cBvh"}},{"cell_type":"code","source":["word2idx = data_configs['word2idx']\n","eos_index = data_configs['eos_symbol']\n","model_name = 'transformer'\n","vocab_size = data_configs['vocab_size']\n","MAX_SEQUENCE = 25\n","batch_size = 2\n","epochs = 30\n","valid_split = 0.1\n","\n","kargs = {\n","    'model_name':model_name,\n","    'num_layers':2,\n","    'd_model':512,\n","    'num_heads':8,\n","    'dff':2048,\n","    'input_vocab_size':vocab_size,\n","    'target_vocab_size':vocab_size,\n","    'eos_token_ids':word2idx[eos_index],\n","    'rate':0.1,\n","    'maximum_position_encoding':MAX_SEQUENCE\n","}"],"metadata":{"id":"3zd0XmumcKpe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 모델 생성"],"metadata":{"id":"KI-ad7G7g8oq"}},{"cell_type":"markdown","source":["### position encoding"],"metadata":{"id":"iYAJ_cMphHyv"}},{"cell_type":"code","source":["### 임베딩 벡터 각 인덱스에 적용할 각도 생성 함수 정의\n","def get_angles(pos, i, d_model):\n","    angle_rates = 1/np.power(10000, (2*i//2) / np.float32(d_model))\n","    return pos * angle_rates"],"metadata":{"id":"kUrmHfXBhFOA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### 임베깅 벡터 각 인덱스에 적용할 각도 생성 함수 해석 --> 매개변수 해석\n","'''\n","1. pos : 문장을 구성하고 있는 단어의 위치(0,...,24) --> reshape --> (25,1)\n","2. 임베딩 벡터의 인덱스(0,...,511)  --> reshape --> (1, 512)\n","'''\n","angle_rads = get_angles(np.arange(25).reshape(25,1), np.arange(512).reshape(1,512), 512)\n","\n","# 결과 확인하기\n","print(f'단어 별로 생성된 임베딩 각도 : \\n{angle_rads}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6rX16fIKjqCx","outputId":"4e3b4bfd-a346-4df5-9f59-c2ca8e339095"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["단어 별로 생성된 임베딩 각도 : \n","[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n","  0.00000000e+00 0.00000000e+00]\n"," [1.00000000e+00 9.82171889e-01 9.64661620e-01 ... 1.05544960e-04\n","  1.03663293e-04 1.01815172e-04]\n"," [2.00000000e+00 1.96434378e+00 1.92932324e+00 ... 2.11089920e-04\n","  2.07326586e-04 2.03630344e-04]\n"," ...\n"," [2.20000000e+01 2.16077816e+01 2.12225556e+01 ... 2.32198912e-03\n","  2.28059244e-03 2.23993379e-03]\n"," [2.30000000e+01 2.25899535e+01 2.21872173e+01 ... 2.42753408e-03\n","  2.38425574e-03 2.34174896e-03]\n"," [2.40000000e+01 2.35721253e+01 2.31518789e+01 ... 2.53307904e-03\n","  2.48791903e-03 2.44356413e-03]]\n"]}]},{"cell_type":"code","source":["### pos : 문장을 구성하고 있는 단어의 위치 예시\n","copy_array = np.arange(25)[:, np.newaxis]\n","print(copy_array)"],"metadata":{"id":"PmQPJ6KDnXhV","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e597698b-3745-462e-e4f3-bf5c20016fb8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0]\n"," [ 1]\n"," [ 2]\n"," [ 3]\n"," [ 4]\n"," [ 5]\n"," [ 6]\n"," [ 7]\n"," [ 8]\n"," [ 9]\n"," [10]\n"," [11]\n"," [12]\n"," [13]\n"," [14]\n"," [15]\n"," [16]\n"," [17]\n"," [18]\n"," [19]\n"," [20]\n"," [21]\n"," [22]\n"," [23]\n"," [24]]\n"]}]},{"cell_type":"code","source":["np.arange(512)[np.newaxis, :]"],"metadata":{"id":"cscqc8mApA6k","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b03fce41-c82b-4a7c-e1fc-132e53666523"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n","         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n","         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n","         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n","         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n","         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n","         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n","         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n","        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n","        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n","        130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n","        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n","        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n","        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n","        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n","        195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n","        208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n","        221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n","        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n","        247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n","        260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n","        273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n","        286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n","        299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n","        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n","        325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n","        338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n","        351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n","        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n","        377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n","        390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n","        403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n","        416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n","        429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n","        442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n","        455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n","        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n","        481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n","        494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n","        507, 508, 509, 510, 511]])"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["def get_angles_test(i, d_model):\n","    angle_rates = 1/np.power(10000, (2*i//2) / np.float32(d_model))\n","    return angle_rates\n","\n","angle_rates = get_angles_test(np.arange(512).reshape(1,512), 512)\n","\n","# 결과 확인하기\n","print(angle_rates)"],"metadata":{"id":"kKZQuKhUogX2","colab":{"base_uri":"https://localhost:8080/"},"outputId":"12797d10-f529-4425-af05-6ce9a856e9ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1.00000000e+00 9.82171889e-01 9.64661620e-01 9.47463526e-01\n","  9.30572041e-01 9.13981699e-01 8.97687132e-01 8.81683067e-01\n","  8.65964323e-01 8.50525815e-01 8.35362547e-01 8.20469611e-01\n","  8.05842188e-01 7.91475544e-01 7.77365030e-01 7.63506080e-01\n","  7.49894209e-01 7.36525012e-01 7.23394163e-01 7.10497411e-01\n","  6.97830585e-01 6.85389584e-01 6.73170382e-01 6.61169026e-01\n","  6.49381632e-01 6.37804384e-01 6.26433537e-01 6.15265410e-01\n","  6.04296390e-01 5.93522927e-01 5.82941535e-01 5.72548788e-01\n","  5.62341325e-01 5.52315842e-01 5.42469094e-01 5.32797895e-01\n","  5.23299115e-01 5.13969680e-01 5.04806572e-01 4.95806824e-01\n","  4.86967525e-01 4.78285814e-01 4.69758882e-01 4.61383968e-01\n","  4.53158364e-01 4.45079406e-01 4.37144481e-01 4.29351021e-01\n","  4.21696503e-01 4.14178451e-01 4.06794432e-01 3.99542056e-01\n","  3.92418976e-01 3.85422887e-01 3.78551525e-01 3.71802666e-01\n","  3.65174127e-01 3.58663762e-01 3.52269465e-01 3.45989166e-01\n","  3.39820833e-01 3.33762469e-01 3.27812115e-01 3.21967844e-01\n","  3.16227766e-01 3.10590022e-01 3.05052789e-01 2.99614274e-01\n","  2.94272718e-01 2.89026391e-01 2.83873596e-01 2.78812667e-01\n","  2.73841963e-01 2.68959879e-01 2.64164832e-01 2.59455272e-01\n","  2.54829675e-01 2.50286543e-01 2.45824407e-01 2.41441822e-01\n","  2.37137371e-01 2.32909659e-01 2.28757320e-01 2.24679009e-01\n","  2.20673407e-01 2.16739217e-01 2.12875166e-01 2.09080004e-01\n","  2.05352503e-01 2.01691455e-01 1.98095678e-01 1.94564006e-01\n","  1.91095297e-01 1.87688429e-01 1.84342299e-01 1.81055824e-01\n","  1.77827941e-01 1.74657605e-01 1.71543790e-01 1.68485488e-01\n","  1.65481710e-01 1.62531484e-01 1.59633854e-01 1.56787884e-01\n","  1.53992653e-01 1.51247255e-01 1.48550802e-01 1.45902422e-01\n","  1.43301257e-01 1.40746466e-01 1.38237223e-01 1.35772714e-01\n","  1.33352143e-01 1.30974726e-01 1.28639694e-01 1.26346292e-01\n","  1.24093776e-01 1.21881418e-01 1.19708503e-01 1.17574327e-01\n","  1.15478198e-01 1.13419440e-01 1.11397386e-01 1.09411381e-01\n","  1.07460783e-01 1.05544960e-01 1.03663293e-01 1.01815172e-01\n","  1.00000000e-01 9.82171889e-02 9.64661620e-02 9.47463526e-02\n","  9.30572041e-02 9.13981699e-02 8.97687132e-02 8.81683067e-02\n","  8.65964323e-02 8.50525815e-02 8.35362547e-02 8.20469611e-02\n","  8.05842188e-02 7.91475544e-02 7.77365030e-02 7.63506080e-02\n","  7.49894209e-02 7.36525012e-02 7.23394163e-02 7.10497411e-02\n","  6.97830585e-02 6.85389584e-02 6.73170382e-02 6.61169026e-02\n","  6.49381632e-02 6.37804384e-02 6.26433537e-02 6.15265410e-02\n","  6.04296390e-02 5.93522927e-02 5.82941535e-02 5.72548788e-02\n","  5.62341325e-02 5.52315842e-02 5.42469094e-02 5.32797895e-02\n","  5.23299115e-02 5.13969680e-02 5.04806572e-02 4.95806824e-02\n","  4.86967525e-02 4.78285814e-02 4.69758882e-02 4.61383968e-02\n","  4.53158364e-02 4.45079406e-02 4.37144481e-02 4.29351021e-02\n","  4.21696503e-02 4.14178451e-02 4.06794432e-02 3.99542056e-02\n","  3.92418976e-02 3.85422887e-02 3.78551525e-02 3.71802666e-02\n","  3.65174127e-02 3.58663762e-02 3.52269465e-02 3.45989166e-02\n","  3.39820833e-02 3.33762469e-02 3.27812115e-02 3.21967844e-02\n","  3.16227766e-02 3.10590022e-02 3.05052789e-02 2.99614274e-02\n","  2.94272718e-02 2.89026391e-02 2.83873596e-02 2.78812667e-02\n","  2.73841963e-02 2.68959879e-02 2.64164832e-02 2.59455272e-02\n","  2.54829675e-02 2.50286543e-02 2.45824407e-02 2.41441822e-02\n","  2.37137371e-02 2.32909659e-02 2.28757320e-02 2.24679009e-02\n","  2.20673407e-02 2.16739217e-02 2.12875166e-02 2.09080004e-02\n","  2.05352503e-02 2.01691455e-02 1.98095678e-02 1.94564006e-02\n","  1.91095297e-02 1.87688429e-02 1.84342299e-02 1.81055824e-02\n","  1.77827941e-02 1.74657605e-02 1.71543790e-02 1.68485488e-02\n","  1.65481710e-02 1.62531484e-02 1.59633854e-02 1.56787884e-02\n","  1.53992653e-02 1.51247255e-02 1.48550802e-02 1.45902422e-02\n","  1.43301257e-02 1.40746466e-02 1.38237223e-02 1.35772714e-02\n","  1.33352143e-02 1.30974726e-02 1.28639694e-02 1.26346292e-02\n","  1.24093776e-02 1.21881418e-02 1.19708503e-02 1.17574327e-02\n","  1.15478198e-02 1.13419440e-02 1.11397386e-02 1.09411381e-02\n","  1.07460783e-02 1.05544960e-02 1.03663293e-02 1.01815172e-02\n","  1.00000000e-02 9.82171889e-03 9.64661620e-03 9.47463526e-03\n","  9.30572041e-03 9.13981699e-03 8.97687132e-03 8.81683067e-03\n","  8.65964323e-03 8.50525815e-03 8.35362547e-03 8.20469611e-03\n","  8.05842188e-03 7.91475544e-03 7.77365030e-03 7.63506080e-03\n","  7.49894209e-03 7.36525012e-03 7.23394163e-03 7.10497411e-03\n","  6.97830585e-03 6.85389584e-03 6.73170382e-03 6.61169026e-03\n","  6.49381632e-03 6.37804384e-03 6.26433537e-03 6.15265410e-03\n","  6.04296390e-03 5.93522927e-03 5.82941535e-03 5.72548788e-03\n","  5.62341325e-03 5.52315842e-03 5.42469094e-03 5.32797895e-03\n","  5.23299115e-03 5.13969680e-03 5.04806572e-03 4.95806824e-03\n","  4.86967525e-03 4.78285814e-03 4.69758882e-03 4.61383968e-03\n","  4.53158364e-03 4.45079406e-03 4.37144481e-03 4.29351021e-03\n","  4.21696503e-03 4.14178451e-03 4.06794432e-03 3.99542056e-03\n","  3.92418976e-03 3.85422887e-03 3.78551525e-03 3.71802666e-03\n","  3.65174127e-03 3.58663762e-03 3.52269465e-03 3.45989166e-03\n","  3.39820833e-03 3.33762469e-03 3.27812115e-03 3.21967844e-03\n","  3.16227766e-03 3.10590022e-03 3.05052789e-03 2.99614274e-03\n","  2.94272718e-03 2.89026391e-03 2.83873596e-03 2.78812667e-03\n","  2.73841963e-03 2.68959879e-03 2.64164832e-03 2.59455272e-03\n","  2.54829675e-03 2.50286543e-03 2.45824407e-03 2.41441822e-03\n","  2.37137371e-03 2.32909659e-03 2.28757320e-03 2.24679009e-03\n","  2.20673407e-03 2.16739217e-03 2.12875166e-03 2.09080004e-03\n","  2.05352503e-03 2.01691455e-03 1.98095678e-03 1.94564006e-03\n","  1.91095297e-03 1.87688429e-03 1.84342299e-03 1.81055824e-03\n","  1.77827941e-03 1.74657605e-03 1.71543790e-03 1.68485488e-03\n","  1.65481710e-03 1.62531484e-03 1.59633854e-03 1.56787884e-03\n","  1.53992653e-03 1.51247255e-03 1.48550802e-03 1.45902422e-03\n","  1.43301257e-03 1.40746466e-03 1.38237223e-03 1.35772714e-03\n","  1.33352143e-03 1.30974726e-03 1.28639694e-03 1.26346292e-03\n","  1.24093776e-03 1.21881418e-03 1.19708503e-03 1.17574327e-03\n","  1.15478198e-03 1.13419440e-03 1.11397386e-03 1.09411381e-03\n","  1.07460783e-03 1.05544960e-03 1.03663293e-03 1.01815172e-03\n","  1.00000000e-03 9.82171889e-04 9.64661620e-04 9.47463526e-04\n","  9.30572041e-04 9.13981699e-04 8.97687132e-04 8.81683067e-04\n","  8.65964323e-04 8.50525815e-04 8.35362547e-04 8.20469611e-04\n","  8.05842188e-04 7.91475544e-04 7.77365030e-04 7.63506080e-04\n","  7.49894209e-04 7.36525012e-04 7.23394163e-04 7.10497411e-04\n","  6.97830585e-04 6.85389584e-04 6.73170382e-04 6.61169026e-04\n","  6.49381632e-04 6.37804384e-04 6.26433537e-04 6.15265410e-04\n","  6.04296390e-04 5.93522927e-04 5.82941535e-04 5.72548788e-04\n","  5.62341325e-04 5.52315842e-04 5.42469094e-04 5.32797895e-04\n","  5.23299115e-04 5.13969680e-04 5.04806572e-04 4.95806824e-04\n","  4.86967525e-04 4.78285814e-04 4.69758882e-04 4.61383968e-04\n","  4.53158364e-04 4.45079406e-04 4.37144481e-04 4.29351021e-04\n","  4.21696503e-04 4.14178451e-04 4.06794432e-04 3.99542056e-04\n","  3.92418976e-04 3.85422887e-04 3.78551525e-04 3.71802666e-04\n","  3.65174127e-04 3.58663762e-04 3.52269465e-04 3.45989166e-04\n","  3.39820833e-04 3.33762469e-04 3.27812115e-04 3.21967844e-04\n","  3.16227766e-04 3.10590022e-04 3.05052789e-04 2.99614274e-04\n","  2.94272718e-04 2.89026391e-04 2.83873596e-04 2.78812667e-04\n","  2.73841963e-04 2.68959879e-04 2.64164832e-04 2.59455272e-04\n","  2.54829675e-04 2.50286543e-04 2.45824407e-04 2.41441822e-04\n","  2.37137371e-04 2.32909659e-04 2.28757320e-04 2.24679009e-04\n","  2.20673407e-04 2.16739217e-04 2.12875166e-04 2.09080004e-04\n","  2.05352503e-04 2.01691455e-04 1.98095678e-04 1.94564006e-04\n","  1.91095297e-04 1.87688429e-04 1.84342299e-04 1.81055824e-04\n","  1.77827941e-04 1.74657605e-04 1.71543790e-04 1.68485488e-04\n","  1.65481710e-04 1.62531484e-04 1.59633854e-04 1.56787884e-04\n","  1.53992653e-04 1.51247255e-04 1.48550802e-04 1.45902422e-04\n","  1.43301257e-04 1.40746466e-04 1.38237223e-04 1.35772714e-04\n","  1.33352143e-04 1.30974726e-04 1.28639694e-04 1.26346292e-04\n","  1.24093776e-04 1.21881418e-04 1.19708503e-04 1.17574327e-04\n","  1.15478198e-04 1.13419440e-04 1.11397386e-04 1.09411381e-04\n","  1.07460783e-04 1.05544960e-04 1.03663293e-04 1.01815172e-04]]\n"]}]},{"cell_type":"code","source":["def positional_encoding(position, d_model):\n","    angle_rads = get_angles(np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model)\n","\n","    # 임베딩 벡터 : 인덱스 --> 짝수\n","    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n","    \n","    # 임베딩 벡터 : 인덱스 --> 홀수\n","    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n","\n","    pos_encoding = angle_rads[np.newaxis, ...]\n","\n","    return tf.cast(pos_encoding, dtype=tf.float32)"],"metadata":{"id":"uaZP5QZnpvPP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### masking"],"metadata":{"id":"kDYIOQJss6UD"}},{"cell_type":"markdown","source":["### 5/26 실습"],"metadata":{"id":"Wa9Uyr8CrFAK"}},{"cell_type":"code","source":["### 패딩 마스킹(padding masking) 구현 함수 정의\n","def create_padding_mask(seq):\n","    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)    \n","    return seq[:,tf.newaxis, tf.newaxis, :]\n","    # return tf.reshape(seq, (seq.shape[0],1,1,seq.shape[1])))"],"metadata":{"id":"pDFJY5BttDuO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### 패딩 마스크 구현 함수 사용 예시\n","# seq = seq * -1e9\n","# print(seq)"],"metadata":{"id":"z5ioev5B18A9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# seq = tf.cast(tf.math.equal(enc_inputs[0], 0), tf.float32)\n","# print(seq)"],"metadata":{"id":"Bgptprc6u2iv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["enc_inputs[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dGAaMNEZwUS2","outputId":"1c3a140e-1ddd-4814-c397-37f137fe352b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([116,  87,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0])"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["### self attention"],"metadata":{"id":"vhgG5zoF24D6"}},{"cell_type":"code","source":["### tensorflow 버전 확인\n","print(tf.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I-pnuO7V5Cmt","outputId":"eac3b6ed-403a-4c2f-b97a-1be8669cacec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.12.0\n"]}]},{"cell_type":"code","source":["def scaled_dot_product_attention(q,k,v,mask):\n","    matmul_qk = tf.linalg.matmul(a=q, b=k, transpose_b=True) \n","    # scale matmul_qk\n","    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n","    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n","\n","    # masking\n","    if mask is not None:\n","        scaled_attention_logits += (mask * -1e9)\n","\n","    # softmax 함수 실행\n","    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n","\n","    # value * 가중치\n","    output = tf.matmul(attention_weights, v)\n","\n","    return output, attention_weights"],"metadata":{"id":"boxNbilq29Cq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### MultiHeadAttention"],"metadata":{"id":"tIZuaaf7hevA"}},{"cell_type":"code","source":["class MultiHeadAttention(tf.keras.layers.Layer):\n","    def __init__(self, **kargs):\n","        super(MultiHeadAttention, self).__init__()\n","        self.num_heads = kargs['num_heads']\n","        self.d_model = kargs['d_model']\n","\n","        assert self.d_model % self.num_heads == 0\n","\n","        self.depth = self.d_model // self.num_heads\n","\n","        self.wq = tf.keras.layers.Dense(kargs['d_model'])\n","        self.wk = tf.keras.layers.Dense(kargs['d_model'])\n","        self.wv = tf.keras.layers.Dense(kargs['d_model'])\n","\n","        self.dense = tf.keras.layers.Dense(kargs['d_model'])\n","\n","    def split_heads(self, x, batch_size):       \n","        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","\n","    def call(self, v, k, q, mask):\n","        batch_size = tf.shape(q)[0]\n","\n","        q = self.wq(q)  # (batch_size, seq_len, d_model)\n","        k = self.wk(k)  # (batch_size, seq_len, d_model)\n","        v = self.wv(v)  # (batch_size, seq_len, d_model)\n","\n","        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n","        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n","        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n","\n","        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n","        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n","        scaled_attention, attention_weights = scaled_dot_product_attention(\n","            q, k, v, mask)\n","\n","        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n","\n","        concat_attention = tf.reshape(scaled_attention, \n","                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n","\n","        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n","\n","        return output, attention_weights"],"metadata":{"id":"EKE2GUVRhkbl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### q, k, v 행렬 생성 확인\n","\n","# enc_inputs --> Embedding layer --> 생성되는 임베딩 배열 --> 문장 1개 단위 모양 : (1,25,512)\n","input = tf.keras.Input(shape=(1,25,512))\n","\n","# 입력 데이터 --> Dense layer 통과 --> 가중치 행렬과 연산 --> q, k, v 생성\n","wq = tf.keras.layers.Dense(units=512)\n","wk = tf.keras.layers.Dense(units=512)\n","wv = tf.keras.layers.Dense(units=512)\n","\n","q = wq(input)\n","k = wk(input)\n","v = wv(input)\n","\n","# 결과 확인하기\n","print(q.shape)\n","print(k.shape)\n","print(v.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GJnGdkhRkdaC","outputId":"948b772b-35da-4863-c9d5-ae53976a9239"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(None, 1, 25, 512)\n","(None, 1, 25, 512)\n","(None, 1, 25, 512)\n"]}]},{"cell_type":"markdown","source":["### FFN"],"metadata":{"id":"dplLyqIrsnx8"}},{"cell_type":"code","source":["def point_wise_feed_forward_network(**kargs):\n","    return tf.keras.Sequential([\n","        tf.keras.layers.Dense(units=kargs['dff'], activation='relu'),\n","        tf.keras.layers.Dense(units=kargs['d_model'])\n","    ])"],"metadata":{"id":"9Pr1kZQGswE3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Encoder Layer"],"metadata":{"id":"6Xvl3Jwq5Lsj"}},{"cell_type":"code","source":["class EncoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, **kargs):\n","        super(EncoderLayer, self).__init__()\n","\n","        self.mha = MultiHeadAttention(**kargs)\n","        self.ffn = point_wise_feed_forward_network(**kargs)\n","\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout1 = tf.keras.layers.Dropout(kargs['rate'])\n","        self.dropout2 = tf.keras.layers.Dropout(kargs['rate'])\n","    def call(self, x, mask):\n","        attn_output, _ = self.mha(x,x,x,mask)\n","        attn_output = self.dropout1(attn_output)\n","        out1 = self.layernorm1(x + attn_output)\n","        ffn_output = self.ffn(out1)\n","        ffn_output = self.dropout2(ffn_output)\n","        out2 = self.layernorm2(out1+ffn_output)\n","        return out2"],"metadata":{"id":"fx3ZGarZ5SVK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Encoder"],"metadata":{"id":"L1tpdQuyFpk9"}},{"cell_type":"code","source":["class Encoder(tf.keras.layers.Layer):\n","    def __init__(self, **kargs):\n","        super(Encoder, self).__init__()\n","\n","        self.d_model = kargs['d_model']\n","        self.num_layers = kargs['num_layers']\n","\n","        self.embedding = tf.keras.layers.Embedding(kargs['input_vocab_size'], self.d_model)\n","        self.pos_encoding = positional_encoding(kargs['maximum_position_encoding'], \n","                                                self.d_model)\n","\n","\n","        self.enc_layers = [EncoderLayer(**kargs) for _ in range(self.num_layers)]\n","\n","        self.dropout = tf.keras.layers.Dropout(kargs['rate'])\n","\n","    def call(self, x, mask):\n","\n","        seq_len = tf.shape(x)[1]\n","\n","        # adding embedding and position encoding.\n","        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n","        # x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[:, :seq_len, :]\n","\n","        x = self.dropout(x)\n","\n","        for i in range(self.num_layers):\n","            x = self.enc_layers[i](x, mask)\n","\n","        return x  # (batch_size, input_seq_len, d_model)"],"metadata":{"id":"knuOlp3y-CIH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Encoder 객체 생성\n","encoder = Encoder(**kargs)"],"metadata":{"id":"b1WWG6lZHXLd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### 입력 데이터 생성 --> Encoder 클래스 --> 결과 값 추출\n","\n","# mask 생성\n","enc_padding_mask = create_padding_mask(enc_inputs)\n","\n","# call() 함수 호출\n","enc_output = encoder.call(enc_inputs, enc_padding_mask)\n","print(enc_output)\n","print(enc_output.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r9qvLs3tJBf_","outputId":"a5357f24-1c4f-468f-a960-541e44f44888"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[[ 3.44942838e-01 -2.11669159e+00 -3.79023552e-02 ...  5.57053983e-01\n","   -4.45747912e-01 -7.38333881e-01]\n","  [ 8.58155251e-01 -2.37815475e+00  3.81547719e-01 ...  4.83715981e-01\n","   -4.63531494e-01 -6.78970635e-01]\n","  [ 8.99092615e-01 -2.96937084e+00  3.11517656e-01 ...  6.24412894e-01\n","   -4.86593038e-01 -5.60582638e-01]\n","  ...\n","  [ 5.73798597e-01 -2.69557405e+00 -2.01548606e-01 ...  6.77049458e-01\n","   -7.16934979e-01 -3.78748365e-02]\n","  [ 9.49558765e-02 -2.65950894e+00 -6.86962664e-01 ...  6.87113345e-01\n","   -7.99432039e-01 -7.11470917e-02]\n","  [ 7.23279919e-03 -2.25313592e+00 -1.04625964e+00 ...  6.18758202e-01\n","   -8.59830618e-01 -1.57082051e-01]]\n","\n"," [[ 4.66473907e-01 -1.99182892e+00 -3.10489181e-02 ...  4.64415967e-01\n","   -1.19833566e-01 -5.17452955e-01]\n","  [ 9.60671067e-01 -2.26855803e+00  4.59999174e-01 ...  4.12631631e-01\n","   -1.52203068e-01 -4.61881369e-01]\n","  [ 1.04618597e+00 -2.90945625e+00  3.82258326e-01 ...  5.26612997e-01\n","   -1.40830308e-01 -3.69827062e-01]\n","  ...\n","  [ 7.34801650e-01 -2.56737041e+00 -1.77665114e-01 ...  5.85199058e-01\n","   -2.97483951e-01  1.97578713e-01]\n","  [ 2.31254101e-01 -2.51136899e+00 -6.56000316e-01 ...  5.52715778e-01\n","   -3.73563975e-01  1.74639553e-01]\n","  [ 1.60366997e-01 -2.12274194e+00 -1.03431904e+00 ...  4.81453598e-01\n","   -4.59171355e-01  8.86775628e-02]]\n","\n"," [[ 4.99113679e-01 -1.86681724e+00 -2.36210302e-02 ...  5.23917377e-01\n","   -8.47988799e-02 -5.22038817e-01]\n","  [ 1.00847840e+00 -2.19192696e+00  3.90315473e-01 ...  5.39338946e-01\n","   -1.14331827e-01 -4.56566811e-01]\n","  [ 1.01328838e+00 -2.79565382e+00  3.08153182e-01 ...  6.18174970e-01\n","   -1.99951455e-01 -3.57362896e-01]\n","  ...\n","  [ 7.59394407e-01 -2.43759322e+00 -1.55682936e-01 ...  6.81756139e-01\n","   -2.54993618e-01  1.85073689e-01]\n","  [ 2.44903058e-01 -2.37615204e+00 -6.32610798e-01 ...  6.77169859e-01\n","   -3.11105162e-01  1.37612462e-01]\n","  [ 1.61921546e-01 -1.99686790e+00 -1.01853645e+00 ...  6.02738261e-01\n","   -3.96771640e-01  4.73494902e-02]]\n","\n"," ...\n","\n"," [[ 4.29593265e-01 -2.01922512e+00  1.89463701e-03 ...  4.92417455e-01\n","   -1.29600212e-01 -4.74757731e-01]\n","  [ 1.00046039e+00 -2.24694276e+00  4.66586292e-01 ...  5.06463706e-01\n","   -1.53072193e-01 -4.97008264e-01]\n","  [ 9.80297685e-01 -2.85246849e+00  3.80463958e-01 ...  5.92298925e-01\n","   -2.21975997e-01 -3.73414934e-01]\n","  ...\n","  [ 7.01386988e-01 -2.55401707e+00 -1.37578189e-01 ...  6.37959480e-01\n","   -3.34596217e-01  1.72881037e-01]\n","  [ 2.05759272e-01 -2.49536824e+00 -6.16101980e-01 ...  6.03915095e-01\n","   -4.03959215e-01  1.43657744e-01]\n","  [ 1.32622123e-01 -2.10179329e+00 -9.88240838e-01 ...  5.28722584e-01\n","   -4.91824478e-01  5.85995875e-02]]\n","\n"," [[ 4.90885884e-01 -1.77808225e+00  1.31967524e-02 ...  5.02411544e-01\n","   -2.84611583e-02 -4.77932513e-01]\n","  [ 1.07492530e+00 -2.02934289e+00  4.82362151e-01 ...  5.39140403e-01\n","   -4.69063818e-02 -5.08922219e-01]\n","  [ 1.04122829e+00 -2.66974783e+00  3.73524964e-01 ...  6.42653883e-01\n","   -1.15606643e-01 -4.13938284e-01]\n","  ...\n","  [ 7.82021463e-01 -2.31748509e+00 -8.94056559e-02 ...  7.58807302e-01\n","   -2.13119537e-01  1.73945218e-01]\n","  [ 2.64255911e-01 -2.26004839e+00 -5.61648726e-01 ...  7.65461862e-01\n","   -2.79774427e-01  1.21691048e-01]\n","  [ 1.62431344e-01 -1.87496579e+00 -9.50744629e-01 ...  6.96450830e-01\n","   -3.54152113e-01  1.96959339e-02]]\n","\n"," [[ 4.27026451e-01 -2.00449562e+00 -5.98193612e-03 ...  4.55690473e-01\n","   -1.39337227e-01 -4.67238963e-01]\n","  [ 9.98599589e-01 -2.23500609e+00  4.52022254e-01 ...  4.68714267e-01\n","   -1.59405187e-01 -4.88670737e-01]\n","  [ 9.77800906e-01 -2.84079647e+00  3.66157085e-01 ...  5.51968932e-01\n","   -2.24349946e-01 -3.64191711e-01]\n","  ...\n","  [ 7.01103926e-01 -2.54491019e+00 -1.43801466e-01 ...  5.99513173e-01\n","   -3.38180602e-01  1.85110077e-01]\n","  [ 2.04466715e-01 -2.48815131e+00 -6.23017311e-01 ...  5.68325460e-01\n","   -4.09129530e-01  1.57915577e-01]\n","  [ 1.31825805e-01 -2.09808683e+00 -9.94142413e-01 ...  4.95639116e-01\n","   -4.94143605e-01  7.19190389e-02]]], shape=(20, 25, 512), dtype=float32)\n","(20, 25, 512)\n"]}]}]}